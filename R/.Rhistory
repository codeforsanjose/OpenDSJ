c0 = (r == 0) & (pi > pcut)  #logical vector - true if actual 0 but predict 1
# SEND
return(mean(weight1 * c1 + weight0 * c0))
}
optimalCP <- numeric(0)
# FULL
# cost: 1:2
for (i in 1:length(searchgrid)) {
pcut.changes <- result[i, 1]
# assign the cost to the 2nd col
result[i, 2] <- cost2(train.train$V322, predict(glm2, type = "response"), pcut = pcut.changes, weight1 = 2)
}
for (i in 1:length(searchgrid)) {
pcut.changes <- result[i, 1]
# assign the cost to the 2nd col
result[i, 2] <- cost3a(train.train$V322, predict(glm2, type = "response"), pcut = pcut.changes, weight1 = 2)
}
plot(result, ylab = "Cost in Training Set", main ="full model, cost 1:2", xlab="probability")
for (i in 1:length(searchgrid)) {
pcut.changes <- result[i, 1]
# assign the cost to the 2nd col
result[i, 2] <- cost3a(train.train$V322, predict(glm2, type = "response"), pcut = pcut.changes, weight1 = 5)
}
plot(result, ylab = "Cost in Training Set", main ="full model, cost 1:2", xlab="probability")
inds <- which(result[,2] == min(result[,2]), arr.ind = TRUE)
optimalCP[1] <- result[inds,][1]
optimalCP
cost1 <- function(r, pi) {
mean(((r == 0) & (pi > pcut)) | ((r == 1) & (pi < pcut)))
}
# Asymmetric cost - we are double penalizing getting 1 wrong
cost2 <- function(r, pi) {
weight1 = 2
weight0 = 1
c1 = (r == 1) & (pi < pcut)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > pcut)  #logical vecotr - true if actual 0 but predict 1
return(mean(weight1 * c1 + weight0 * c0))
}
cost3a <- function(r, pi, pcut,weight1) {
weight0 = 1
c1 = (r == 1) & (pi < pcut)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > pcut)  #logical vector - true if actual 0 but predict 1
# SEND
return(mean(weight1 * c1 + weight0 * c0))
}
cost3c <- function(r, pi) {
weight1 = 10
weight0 = 1
c1 = (r == 1) & (pi < pcut)  #logical vector - true if actual 1 but predict 0
c0 = (r == 0) & (pi > pcut)  #logical vecotr - true if actual 0 but predict 1
return(mean(weight1 * c1 + weight0 * c0))
}
for (i in 1:length(searchgrid)) {
pcut <- result0[i, 1]
result0[i, 2] <- cv.glm(data = train, glmfit = glm1, cost = cost3c, K = 5)$delta[2]
}
searchgrid = seq(0.01, 0.6, 0.02)
result0 = cbind(searchgrid, NA)
result1 = cbind(searchgrid, NA)
result2 = cbind(searchgrid, NA)
for (i in 1:length(searchgrid)) {
pcut <- result0[i, 1]
result0[i, 2] <- cv.glm(data = train, glmfit = glm1, cost = cost3c, K = 5)$delta[2]
}
library(boot)
for (i in 1:length(searchgrid)) {
pcut <- result0[i, 1]
result0[i, 2] <- cv.glm(data = train, glmfit = glm1, cost = cost3c, K = 5)$delta[2]
}
train <- read.csv("/Users/Vivek/Dropbox/Watson/train5.csv", header=F, sep = ",")
train <- read.csv("/Users/Vivek/Dropbox/Watson/train5.csv", header=F, sep = ",")
train <- read.csv("/Users/Vivek/Dropbox/Watson/trainV5.csv", header=F, sep = ",")
head(train)
filepath <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_business.json"
filepath <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_business.json"
install.packages("stringr") # Hadley Wickham's magic package for working with strings.
install.packages("RJSONIO") # Alows us to parse the JSON files.
library(RJSONIO)
library(stringr)
unpackJSON <- function(filepath){
con <- file(filepath, "r") # open connection and pull file given with "filepath"
input <- readLines(con, -1L) # read the file in "line by line" into an R object
jsonData <- sapply(input,fromJSON) # Run fromJSON() on each element in input.
close(con) # close the connection that was made when con was created.
dimnames(jsonData)[2] <- NULL # This drops the long names that each observation was given by fromJSON()
varNames <- dimnames(jsonData)[1] # Stores the variable names (which are the rownames right now)
jsonDataAsDataFrame <- data.frame(jsonData) # Take long list and colate by observation into a data.frame
jsonDataAsDataFrameTransposed <- as.data.frame(t(jsonDataAsDataFrame)) # Transpose so the variables are the columns ans the observations are the rows.
return(jsonDataAsDataFrameTransposed) # Only return this last data frame when you run the function, scrap everything else.
} # closing UnpackJSON function
maxNumberOfElementsPerVar<- function(rawDataFrame){
maxElementsForEachVar <- list() # This is a storage container that will store the max number of elements any var can have.
for (i in 1:ncol(rawDataFrame)){
oneRawVar <- rawDataFrame[,i]
oneVarLengths <- list() # This is a container that will hold how many entries each observation has for the ith variable
for (j in 1:length(oneRawVar)){
oneVarLengths[[j]] <- length(oneRawVar[[j]]) # For the ith variable how many elements does the jth observation have.
} # Ends loop across each observation-variable pair for the ith variable.
maxElementsForEachVar[[i]] <- max(unlist(oneVarLengths))
}# Ends for loop across variables/columns
unlist(maxElementsForEachVar)
}# ends maxNumberOfElementsPerVar
getwd()
exampleRawDataFrame <- unpackJSON("yelp_academic_dataset_business.json")
exampleRawDataFrame <- unpackJSON(filepath)
exampleRawDataFrame
str(exampleRawDataFrame, max.level=1)
head(exampleRawDataFrame)
str(exampleRawDataFrame, max.level=1)
createNewVars()
rawDataFrame <- unpackJSON("yelp_academic_dataset_business.json") # used for testing the function
rawDataFrame <- unpackJSON(filepath) # used for testing the function
createNewVars <- function(rawDataFrame){
numberOfNewVars <- maxNumberOfElementsPerVar(rawDataFrame) # Determine how many new variables each old variable needs
for (i in 1:ncol(rawDataFrame)){ # Loop across the variables
if (numberOfNewVars[i]>1){ # does the ith variable have any observations with more than one element, if so do the following.
varName <- names(rawDataFrame[i]) # Store the variable name
tempVar <- lapply(rawDataFrame[[i]], function(v) { c(v, rep(NA, numberOfNewVars[i]-length(v)))}) # Fill in with NA so the shape is square
tempDataFrame <- data.frame(matrix(unlist(tempVar,use.names=FALSE),nrow=nrow(rawDataFrame),ncol=numberOfNewVars[i],byrow=TRUE), stringsAsFactors=FALSE) # make the variable its own data frame
names(tempDataFrame) <- paste(varName,seq(1:numberOfNewVars[i]),sep="") # name the new variables based on the old one.
combinedDataFrame <- data.frame(rawDataFrame,tempDataFrame) #combine the original data with the new expanded one
} # ends If Loop
} #ends i loop over the vars
}
newDataFrame <- combinedDataFrame
createNewVars()
unpackedRawData <- unpackJSON(filepath) # You need to provide the path on your machine here.
c1IsRestaurantsDataFrame <- subset(expandedDataFrame, categories1=="Restaurants")
expandedDataFrame <- createNewVars(unpackedRawData)
c1IsRestaurantsDataFrame <- subset(expandedDataFrame, categories1=="Restaurants")
c1IsRestaurantsDataFrames
expandedDataFrame
expandedDataFrame
expandedDataFrame <- createNewVars(unpackedRawData)
expandedDataFrame
filereview <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_review.json"
filebusiness <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_business.json"
library(RJSONIO)
library(stringr)
unpackJSON <- function(filepath){
con <- file(filepath, "r") # open connection and pull file given with "filepath"
input <- readLines(con, -1L) # read the file in "line by line" into an R object
jsonData <- sapply(input,fromJSON) # Run fromJSON() on each element in input.
close(con) # close the connection that was made when con was created.
dimnames(jsonData)[2] <- NULL # This drops the long names that each observation was given by fromJSON()
varNames <- dimnames(jsonData)[1] # Stores the variable names (which are the rownames right now)
jsonDataAsDataFrame <- data.frame(jsonData) # Take long list and colate by observation into a data.frame
jsonDataAsDataFrameTransposed <- as.data.frame(t(jsonDataAsDataFrame)) # Transpose so the variables are the columns ans the observations are the rows.
return(jsonDataAsDataFrameTransposed) # Only return this last data frame when you run the function, scrap everything else.
}
maxNumberOfElementsPerVar<- function(rawDataFrame){
maxElementsForEachVar <- list() # This is a storage container that will store the max number of elements any var can have.
for (i in 1:ncol(rawDataFrame)){
oneRawVar <- rawDataFrame[,i]
oneVarLengths <- list() # This is a container that will hold how many entries each observation has for the ith variable
for (j in 1:length(oneRawVar)){
oneVarLengths[[j]] <- length(oneRawVar[[j]]) # For the ith variable how many elements does the jth observation have.
} # Ends loop across each observation-variable pair for the ith variable.
maxElementsForEachVar[[i]] <- max(unlist(oneVarLengths))
}# Ends for loop across variables/columns
unlist(maxElementsForEachVar)
}
createNewVars <- function(rawDataFrame){
numberOfNewVars <- maxNumberOfElementsPerVar(rawDataFrame) # Determine how many new variables each old variable needs
for (i in 1:ncol(rawDataFrame)){ # Loop across the variables
if (numberOfNewVars[i]>1){ # does the ith variable have any observations with more than one element, if so do the following.
varName <- names(rawDataFrame[i]) # Store the variable name
tempVar <- lapply(rawDataFrame[[i]], function(v) { c(v, rep(NA, numberOfNewVars[i]-length(v)))}) # Fill in with NA so the shape is square
tempDataFrame <- data.frame(matrix(unlist(tempVar,use.names=FALSE),nrow=nrow(rawDataFrame),ncol=numberOfNewVars[i],byrow=TRUE), stringsAsFactors=FALSE) # make the variable its own data frame
names(tempDataFrame) <- paste(varName,seq(1:numberOfNewVars[i]),sep="") # name the new variables based on the old one.
combinedDataFrame <- data.frame(rawDataFrame,tempDataFrame) #combine the original data with the new expanded one
} # ends If Loop
} #ends i loop over the vars
}
getwd()
rawReviews <- unpackJSON(filereview) # used for testing
filebusiness <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_business.json"
filereview <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_review.json"
rawReviews <- unpackJSON(filereview) # used for testing
unpackedRawData <- unpackJSON(filebusiness) # You need to provide the path on your machine here.
expandedDataFrame <- createNewVars(unpackedRawData)
c1IsRestaurantsDataFrame <- subset(expandedDataFrame, categories1=="Restaurants")
expandedDataFrame[335,]
c1IsRestaurantsDataFrame
c1IsRestaurantsDataFrame <- subset(expandedDataFrame, categories1=="Restaurants")
filebusiness <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_business.json"
filereview <- "/Volumes/Windows/yelp_phoenix_academic_dataset 2/yelp_academic_dataset_review.json"
exampleRawDataFrame <- unpackJSON(filebusiness)
exampleRawDataFrame
str(exampleRawDataFrame, max.level=1)
head(exampleRawDataFrame)
rawDataFrame <- unpackJSON("yelp_academic_dataset_business.json") # used for testing the function
rawDataFrame <- unpackJSON(filebusiness) # used for testing the function
unpackedRawData <- unpackJSON(filebusiness) # You need to provide the path on your machine here.
expandedDataFrame <- createNewVars(unpackedRawData)
expandedDataFrame
unpackedRawData
createNewVars <- function(rawDataFrame){
numberOfNewVars <- maxNumberOfElementsPerVar(rawDataFrame) # Determine how many new variables each old variable needs
for (i in 1:ncol(rawDataFrame)){ # Loop across the variables
if (numberOfNewVars[i]>1){ # does the ith variable have any observations with more than one element, if so do the following.
varName <- names(rawDataFrame[i]) # Store the variable name
tempVar <- lapply(rawDataFrame[[i]], function(v) { c(v, rep(NA, numberOfNewVars[i]-length(v)))}) # Fill in with NA so the shape is square
tempDataFrame <- data.frame(matrix(unlist(tempVar,use.names=FALSE),nrow=nrow(rawDataFrame),ncol=numberOfNewVars[i],byrow=TRUE), stringsAsFactors=FALSE) # make the variable its own data frame
names(tempDataFrame) <- paste(varName,seq(1:numberOfNewVars[i]),sep="") # name the new variables based on the old one.
combinedDataFrame <- data.frame(rawDataFrame,tempDataFrame) #combine the original data with the new expanded one
} # ends If Loop
} #ends i loop over the vars
}
expandedDataFrame <- createNewVars(unpackedRawData)
unpackedRawData
head(unpackedRawData)
str(unpackedRawData)
head(unpackedRawData)
str(unpackedRawData)
expandedDataFrame <- createNewVars(unpackedRawData)
head(expandedDataFrame)
str(expandedDataFrame)
expandedDataFrame <- createNewVars(unpackedRawData)
head(unpackedRawData)
str(unpackedRawData)
head(expandedDataFrame)
expandedDataFrame
expandedDataFrame <- createNewVars(unpackedRawData)
expandedDataFrame
head(unpackedRawData)
str(unpackedRawData)
expandedDataFrame <- createNewVars(unpackedRawData)
head(expandedDataFrame)
str(expandedDataFrame)
expandedDataFrame
a<- c(1, 0, 0)
b<- c(1, 1, 0)
c <- c(1,1,1)
a*b
a*b/(a^2*b^2)
a*b/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2))
(a*b)/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2))
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2))
a<- c(1, 0, 0)
b<- c(1, 1, 0)
c <- c(1,1,1)
a<-a
a<-c
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2))
a<- c(1, 0, 0)
b<- c(1, 1, 0)
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2))
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2)^(1/2))
a<-c
b<- c(1, 1, 0)
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2)^(1/2))
a<-b
b<- c(1, 1, 0)
(a[1]*b[1]+a[2]*b[2]+a[3]*b[3])/((a[1]^2 + a[2]^2 + a[3]^2)^(1/2)*(b[1]^2+b[2]^2+b[3]^2)^(1/2))
?plyr
??plyr
install.package(plyr)
install.packages(plyr)
install.packages("plyr")
anyCategoryIsRestaurants <- subset(expandedDataFrame, isAResturant==TRUE)
cl
clr
clr()
cl()
?clear
??clear
expandedDataFrame <- createNewVars(unpackedRawData)
head(expandedDataFrame)
str(expandedDataFrame)
expandedDataFrame
head(unpackedRawData)
str(unpackedRawData)
exampleRawDataFrame <- unpackJSON(filebusiness)
unpackedRawData <- unpackJSON(filebusiness) # You need to provide the path on your machine here.
exampleRawDataFrame <- unpackJSON(filebusiness)
unpackedRawData <- unpackJSON(filebusiness) # You need to provide the path on your machine here.
expandedDataFrame <- createNewVars(unpackedRawData)
expandedDataFrame
expandedDataFrame <- createNewVars(unpackedRawData)
expandedDataFrame
unpackedRawData
head(unpackedRawData)
unpackedRawData
head(unpackedRawData)
install.packages(c("aplpack", "caTools", "class", "colorspace", "foreign", "gplots", "gss", "gtools", "lattice", "MASS", "Matrix", "mgcv", "mvtnorm", "nlme", "nnet", "party", "RgoogleMaps", "sandwich", "sp", "spatial", "strucchange"))
?nnet
install.packages(twitterR)
install.packages("twitterR")
install.packages("twitteR")
library(twitteR)
rdmTweets <- userTimeline("rdatamining", n=200)
(nDocs <- length(rdmTweets))
install.packages("devtools")
install_github("twitteR", username="geoffjentry")
library(devtools)
install_github("twitteR", username="geoffjentry")
library(twitteR)
rdmTweets <- userTimeline("rdatamining", n=200)
?twitterR
?twitter
?twitteR
install.packages('XML')
require(XML)
mydata.vectors <- character(0)
for (page in c(1:15))
{
# search parameter
twitter_q <- URLencode('#prolife OR #prochoice')
# construct a URL
twitter_url = paste('http://search.twitter.com/search.atom?q=',twitter_q,'&rpp=100&page=', page, sep='')
# fetch remote URL and parse
mydata.xml <- xmlParseDoc(twitter_url, asText=F)
# extract the titles
mydata.vector <- xpathSApply(mydata.xml, '//s:entry/s:title', xmlValue, namespaces =c('s'='http://www.w3.org/2005/Atom'))
# aggregate new tweets with previous tweets
mydata.vectors <- c(mydata.vector, mydata.vectors)
}
length(mydata.vectors)
for (page in c(1:15))
{
# search parameter
twitter_q <- URLencode('#prolife OR #prochoice')
# construct a URL
twitter_url = paste('http://search.twitter.com/search.atom?q=',twitter_q,'&rpp=100&page=', page, sep='')
# fetch remote URL and parse
mydata.xml <- xmlParseDoc(twitter_url, asText=F)
# extract the titles
mydata.vector <- xpathSApply(mydata.xml, '//s:entry/s:title', xmlValue, namespaces =c('s'='http://www.w3.org/2005/Atom'))
# aggregate new tweets with previous tweets
mydata.vectors <- c(mydata.vector, mydata.vectors)
}
3/7
2/7
4/7
3/7
tgmctrain <- read.csv("~/Dropbox/Watson/tgmctrain.csv", header=F)
View(tgmctrain)
summary(tgmctrain)
install.packages("twitteR")
library(devtools)
install_github("twitteR", username="geoffjentry")
library(twitteR)
twitteR
str(twitteR)
A.Contributions.Table.1 <- read.csv("~/Volumes/Windows/OpenDSJ/R/A-Contributions-Table 1.csv", stringsAsFactors=FALSE)
A.Contributions.Table.1 <- read.csv("~/Volumes/Windows/OpenDSJ/R/A-Contributions-Table 1.csv", stringsAsFactors=FALSE)
A.Contributions.Table.1 <- read.csv("/Volumes/Windows/OpenDSJ/R/A-Contributions-Table 1.csv", stringsAsFactors=FALSE)
efile_newest_CSJ_2013_A_contributions <- read.csv("/Volumes/Windows/OpenDSJ/R/efile_newest_CSJ_2013_A_contributions.csv", stringsAsFactors=FALSE)
mayor2013<-efile_newest_CSJ_2013_A_contributions
mayor2014 <- A.Contributions.Table.1
str(mayor2013)
str(mayor2014)
combo <- data.frame(stringsAsFactors=FALSE)
combo <- rbind(mayor2013, mayor2014)
str(combo)
combo$Tran_City <-as.factor(tolower(combo$Tran_City))
levels(combo$Tran_City)
levels(combo$Tran_City) <- sub("^san joe$", "san jose", levels(combo$Tran_City))
levels(combo$Tran_City) <- sub("^san josr$", "san jose", levels(combo$Tran_City))
levels(combo$Tran_City) <- sub("^san  jose$", "san jose", levels(combo$Tran_City))
levels(combo$Tran_City) <- sub("^sj$", "san jose", levels(combo$Tran_City))
combo$Tran_Zip4
combo$Tran_Zip4 <- as.character(combo$Tran_Zip4)
combo$Tran_Zip4
for(i in 1:nrow(combo)) {                 #takes a few mins
if(nchar(combo$Tran_Zip4[i]) == 6)    #looking for cases only when zipcode is 6 char long
{
combo$Tran_Zip4[i] <- gsub("-.*","",combo$Tran_Zip4[i])
}
}
combo$Tran_Zip4 <- clean.zipcodes(combo$Tran_Zip4)
combo$Tran_Zip4
combo$Tran_Date <- as.Date(as.character(combo$Tran_Date), "%m/%d/%Y")
combo$Rpt_Date <- as.Date(as.character(combo$Rpt_Date), "%m/%d/%Y")
combo$From_Date <- as.Date(as.character(combo$From_Date), "%m/%d/%Y")
somemayors <- data.frame(combo$Filer_NamL, combo$Filer_ID, combo$Rpt_Date, combo$From_Date, combo$Tran_Date, combo$Tran_ID, combo$Tran_NamL, combo$Tran_Zip4, combo$Tran_City, combo$Tran_State, combo$Tran_Amt1)
str(somemayors)
mayors <- rename(somemayors, c("combo.Filer_NamL"="Cands", "combo.Filer_ID"="ID", "combo.Rpt_Date"="RDate", "combo.From_Date" = "FDate", "combo.Tran_Date"="TDate",  "combo.Tran_ID" = "TranID","combo.Tran_NamL" = "TranName",
"combo.Tran_Zip4"="Zip", "combo.Tran_City"="City", "combo.Tran_State"="State", "combo.Tran_Amt1"="Amt1"))
library(zipcode)
library(plyr)
mayors <- rename(somemayors, c("combo.Filer_NamL"="Cands", "combo.Filer_ID"="ID", "combo.Rpt_Date"="RDate", "combo.From_Date" = "FDate", "combo.Tran_Date"="TDate",  "combo.Tran_ID" = "TranID","combo.Tran_NamL" = "TranName",
"combo.Tran_Zip4"="Zip", "combo.Tran_City"="City", "combo.Tran_State"="State", "combo.Tran_Amt1"="Amt1"))
str(mayors)
hist(as.numeric(mayors$ID))
hist(as.numeric(mayors$Cands))
sum(subset(mayors, ID == 1359805)$Amt1, na.rm = TRUE)
sum(subset(mayors, ID == 1362187)$Amt1)
sum(subset(mayors, ID == 1362117)$Amt1)
sum(subset(mayors, ID == 1362068)$Amt1)
sum(subset(mayors, ID == 1362068)$Amt1, na.rm = TRUE)
sum(subset(mayors, ID == 820668)$Amt1)
sum(subset(mayors, ID == 744711)$Amt1)
sum(subset(mayors, TranName == "Casino M8trix")$Amt1)
sum(subset(mayors, ID == 743393)$Amt1)
a <- subset(mayors, ID == c(1359805))
b <- subset(mayors, ID == c(1362117))
c <- subset(mayors, ID == c(1362068))
d <- subset(mayors, ID == c(1361139))
e <- subset(mayors, ID == c(1362187))
JustMayoralCampaignsNoPacs <- rbind(a, b,c,d,e)
sum(JustMayoralCampaignsNoPacs$Amt1, na.rm = TRUE)
write.csv(JustMayoralCampaignsNoPacs, file = "ContributionsToMayoral.csv")
jmayoral <- JustMayoralCampaignsNoPacs
jmayoral$ID <- as.character(jmayoral$ID)
aggregate(Amt1 ~ Cands, data = jmayoral, FUN=sum)
str(jmayoral)
summary(jmayoral$ID)
jmayoral$ID
str(jmayoral)
summary(jmayoral$ID)
jmayoral$ID
jmayoral$ID <- as.character(jmayoral$ID)
AllMayoralContributions <- aggregate(Amt1 ~ Zip, data = jmayoral, FUN=sum)
write.csv(AllMayoralContributions, file = "AllMayoralContributionsByZip.csv")
a <- subset(jmayoral, ID == c(1359805))
b <- subset(jmayoral, ID == c(1362117))
c <- subset(jmayoral, ID == c(1362068))
d <- subset(jmayoral, ID == c(1361139))
e <- subset(jmayoral, ID == c(1362187))
str(a)
AMayoralContributions <- aggregate(Amt1 ~ Zip, data = a, FUN=sum)
BMayoralContributions <- aggregate(Amt1 ~ Zip, data = b, FUN=sum)
CMayoralContributions <- aggregate(Amt1 ~ Zip, data = c, FUN=sum)
DMayoralContributions <- aggregate(Amt1 ~ Zip, data = d, FUN=sum)
EMayoralContributions <- aggregate(Amt1 ~ Zip, data = e, FUN=sum)
write.csv(AMayoralContributions, file = "NguyenTotalContributionsByZip.csv")
write.csv(BMayoralContributions, file = "OliverioTotalContributionsByZip.csv")
write.csv(CMayoralContributions, file = "HerreraTotalContributionsByZip.csv")
write.csv(DMayoralContributions, file = "LiccardoTotalContributionsByZip.csv")
write.csv(EMayoralContributions, file = "CorteseTotalContributionsByZip.csv")
xtabs()
xtabs()
sum(subset(mayors, ID == 1361139)$Amt1)
nrow(subset(mayors, ID == 1361139))
sum(subset(mayors, (ID == 1361139 & City == "san jose"))$Amt1)
sum(subset(mayors, ID == 1361139)$Amt1)
sum(subset(mayors, ID == 1366242)$Amt1)
mayors
sum(subset(mayors, ID == 1362187)$Amt1)
nrow(subset(mayors, ID == 1362187))
sum(subset(mayors, (ID == 1362187 & City == "san jose"))$Amt1)
sum(subset(mayors, (ID == 1362187 & City != "san jose"))$Amt1)
580057.4/(552675.7 + 580057.4)
552675.7/(552675.7 + 580057.4)
sum(subset(mayors, ID == 1362187)$Amt1)
combo$Tran_Zip4
for(i in 1:nrow(combo)) {                 #takes a few mins
if(nchar(combo$Tran_Zip4[i]) == 6)    #looking for cases only when zipcode is 6 char long
{
combo$Tran_Zip4[i] <- gsub("-.*","",combo$Tran_Zip4[i])
}
}
combo$Tran_Zip4 <- clean.zipcodes(combo$Tran_Zip4)
combo$Tran_Zip4
combo$Tran_Date <- as.Date(as.character(combo$Tran_Date), "%m/%d/%Y")
combo$Rpt_Date <- as.Date(as.character(combo$Rpt_Date), "%m/%d/%Y")
combo$From_Date <- as.Date(as.character(combo$From_Date), "%m/%d/%Y")
somemayors <- data.frame(combo$Filer_NamL, combo$Filer_ID, combo$Rpt_Date, combo$From_Date, combo$Tran_Date, combo$Tran_ID, combo$Tran_NamL, combo$Tran_Zip4, combo$Tran_City, combo$Tran_State, combo$Tran_Amt1)
str(somemayors)
mayors <- rename(somemayors, c("combo.Filer_NamL"="Cands", "combo.Filer_ID"="ID", "combo.Rpt_Date"="RDate", "combo.From_Date" = "FDate", "combo.Tran_Date"="TDate",  "combo.Tran_ID" = "TranID","combo.Tran_NamL" = "TranName",
"combo.Tran_Zip4"="Zip", "combo.Tran_City"="City", "combo.Tran_State"="State", "combo.Tran_Amt1"="Amt1"))
str(mayors)
mayors$Zip
a <- subset(mayors, ID == c(1359805))
b <- subset(mayors, ID == c(1362117))
c <- subset(mayors, ID == c(1362068))
d <- subset(mayors, ID == c(1361139))
e <- subset(mayors, ID == c(1362187))
JustMayoralCampaignsNoPacs <- rbind(a, b,c,d,e)
sum(JustMayoralCampaignsNoPacs$Amt1, na.rm = TRUE)
setwd("/Users/Vivek/Dropbox/opendisclosure")
write.csv(JustMayoralCampaignsNoPacs, file = "ContributionsToMayoral.csv")
jmayoral <- JustMayoralCampaignsNoPacs
jmayoral
str(jmayoral)
summary(jmayoral$ID)
jmayoral$ID <- as.character(jmayoral$ID)
jmayoral
AllMayoralContributions <- aggregate(Amt1 ~ Zip, data = jmayoral, FUN=sum)
write.csv(AllMayoralContributions, file = "AllMayoralContributionsByZip.csv")
a <- subset(jmayoral, ID == c(1359805))
b <- subset(jmayoral, ID == c(1362117))
c <- subset(jmayoral, ID == c(1362068))
d <- subset(jmayoral, ID == c(1361139))
e <- subset(jmayoral, ID == c(1362187))
AMayoralContributions <- aggregate(Amt1 ~ Zip, data = a, FUN=sum)
BMayoralContributions <- aggregate(Amt1 ~ Zip, data = b, FUN=sum)
CMayoralContributions <- aggregate(Amt1 ~ Zip, data = c, FUN=sum)
DMayoralContributions <- aggregate(Amt1 ~ Zip, data = d, FUN=sum)
EMayoralContributions <- aggregate(Amt1 ~ Zip, data = e, FUN=sum)
write.csv(AMayoralContributions, file = "NguyenTotalContributionsByZip.csv")
write.csv(BMayoralContributions, file = "OliverioTotalContributionsByZip.csv")
write.csv(CMayoralContributions, file = "HerreraTotalContributionsByZip.csv")
write.csv(DMayoralContributions, file = "LiccardoTotalContributionsByZip.csv")
write.csv(EMayoralContributions, file = "CorteseTotalContributionsByZip.csv")
getwd()
setwd("/Volumes/Windows/OpenDSJ/R")
write.csv(AMayoralContributions, file = "NguyenTotalContributionsByZip.csv")
write.csv(BMayoralContributions, file = "OliverioTotalContributionsByZip.csv")
write.csv(CMayoralContributions, file = "HerreraTotalContributionsByZip.csv")
write.csv(DMayoralContributions, file = "LiccardoTotalContributionsByZip.csv")
write.csv(EMayoralContributions, file = "CorteseTotalContributionsByZip.csv")
sum(subset(mayors, ID == 1366242)$Amt1)
sum(subset(mayors, ID == 1361139)$Amt1)
nrow(subset(mayors, ID == 1361139))
sum(subset(mayors, (ID == 1361139 & City == "san jose"))$Amt1)
sum(subset(mayors, (ID == 1361139 & City != "san jose"))$Amt1)
563703.8/(563703.8 + 681146)
681146/(563703.8 + 681146)
nrow(subset(mayors, ID == 1362187))
